<?xml version='1.0'?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd" [
<!ENTITY PLATFORM_NAME "${platform.name}">
<!ENTITY VERSION "${version}">
<!ENTITY YEAR "${year}">
]>
<chapter id="ittms-Architecture_the_Media_Server">
	<title>Media Server Architecture</title>


	<para>
		Media services have played an important role in the traditional
		Time Division Multiplexing (
		<acronym>TDM</acronym>
		)-based telephone network. As the network migrates to an
		Internet Protocol (
		<acronym>IP</acronym>
		)-based environment, media services are also moving to new
		environments.
	</para>
	<para>
		One of the most exciting trends is the emergence and adoption of
		complementary modular standards that leverage the Internet to
		enable media services to be developed, deployed and updated more
		rapidly than before in a network architecture that supports the
		two concepts called
		<emphasis>provisioning-on-demand</emphasis>
		and
		<emphasis>scaling-on-demand</emphasis>
		.
	</para>
	<section id="ittms-High_Level_Component">
		<title>High level components</title>


		<para>
			The Media Server's high degree of modularity benefits the
			application developer in several ways. The already-tight
			code can be further optimized to support applications that
			require small footprints. For example, if
			<acronym>PSTN</acronym>
			interconnection is unnecessary in an application, then the
			D-channel feature can be removed from the Media Server. In
			the future, if the same application is deployed within a
			Signaling System 7 (
			<acronym>SS7</acronym>
			) network, then the appropriate endpoint can be enabled, and
			the application is then compatible.
		</para>
		<mediaobject id="ittms-mms-MMSArchictecture-dia-MMS">
			<imageobject>
				<imagedata align="center" width="550"
					fileref="images/mms-MMSArchictecture-dia-MMS2.jpg" format="PNG"></imagedata>
			</imageobject>
		</mediaobject>
		<para>
			The Media Server architecture assumes that call control
			intelligence lies outside of the Media Server, and is
			handled by an external entity. The Media Server also assumes
			that call controllers will use control procedure described by protocols such as
			<acronym>MGCP</acronym>
			,
			<acronym>MEGACO</acronym>
			or
			<acronym>MSML</acronym>
			, among others. Each specific control module can be plugged
			in directly to the server as a standard deployable unit.
			Utilizing the JBoss Microcontainer for the implementation of
			control protocol-specific communication logic allows for
			simple deployment. It is therefore unnecessary for
			developers to configure low-level transaction and state
			management details, multi-threading, connection-pooling and
			other low-level details and
			<acronym>API</acronym>
			s.
		</para>
		<para>
			The Mobicents Media Server call control intelligence can be
			a JSLEE Application deployed on Mobicents JAIN SLEE Server
			or any other JAIN SLEE container. In case of Mobicents JSLEE
			Server there is already MGCP Resource Adaptor available.
		</para>

		<para>
			Mobicents Media Server can also be controlled from Mobicents
			SIP Servlets or any other SIP Servlets container using any
			of the above call control procedures or using the Mobicents
			JSR-309 Implementation. Mobicents JSR-309 Implementation
			internally leverages MGCP protocol to controll media server.
			Mobicents JSR-309 implementation details is out of scope of
			this document.
		</para>

		<para>
			It is also possible to control the Mobicents Media Server
			from any third party Java application (including standalone
			Java apps) or other technologies like .NET etc as far as
			they follow standrad protocols like MGCP, MEGACO etc. There
			is no dependency on call controller but the protocol used
			between the call controller and Mobicents Media Server.
		</para>


		<para>
			Many key features of Mobicents Media Server are provided by
			integrating individual components operating using generic
			Service Provider Interface. There are two of types of high
			level components: Endpoints and Controllers.
		</para>

		<section id="ittms-Endpoints">
			<title>Endpoints</title>

			<para>
				It is convenient to consider a media gateway as a
				collection of endpoints. An endpoint is a logical
				representation of a physical entity such as an analog
				phone or a channel in a trunk. Endpoints are sources or
				sinks of data and can be either physical or virtual.
				Physical endpoint creation requires hardware
				installation, while software is sufficient for creating
				virtual endpoints. An interface on a gateway that
				terminates at a trunk connected to a
				<acronym>PTSN</acronym>
				switch would be an example of a physical endpoint. An
				audio source in an audio content server would be an
				example of a virtual endpoint.
			</para>

			<para>
				The type of the endpoint determines its functionality.
				Our analysis, so far, has led us to isolate the
				following basic endpoint types:
			</para>
			<itemizedlist>
				<listitem>
					<para>
						digital signal 0 (
						<acronym>DS0</acronym>
						)
					</para>
				</listitem>
				<listitem>
					<para>analog line</para>
				</listitem>
				<listitem>
					<para>announcement server access point</para>
				</listitem>
				<listitem>
					<para>conference bridge access point</para>
				</listitem>
				<listitem>
					<para>packet relay</para>
				</listitem>
				<listitem>
					<para>
						Asynchronous Transfer Mode (
						<acronym>ATM</acronym>
						) "trunk side" interface
					</para>
				</listitem>
			</itemizedlist>
			<para>
				This list is not final: other endpoint types may be
				defined in the future, such as test endpoints which
				could be used to check network quality, or frame-relay
				endpoints that could be used to manage audio channels
				multiplexed over a frame-relay virtual circuit.
			</para>
			<variablelist>
				<title>
					Descriptions of Various Access Point Types
				</title>
				<varlistentry>
					<term>Announcement Server Access Point</term>
					<listitem>
						<para>
							An announcement server endpoint provides
							access, intuitively, to an announcement
							server. Upon receiving requests from the
							call agent, the announcement server
							<quote>plays</quote>
							a specified announcement. A given
							announcement endpoint is not expected to
							support more than one connection at a time.
							Connections to an announcement server are
							typically one-way; they are
							<quote>half-duplex</quote>
							: the announcement server is not expected to
							listen to audio signals from the connection.
							Announcement access points are capable of
							playing announcements; however, these
							endpoints do not have the capability of
							transcoding. To achieve transcoding, a
							Packet Relay must be used. Also note that
							the announcement server endpoint can
							generate tones, such as dual-tone
							multi-frequency (DTMF).
						</para>
					</listitem>
				</varlistentry>
				<varlistentry>
					<term>Interactive Voice Response Access Point</term>
					<listitem>
						<para>
							An Interactive Voice Response (
							<acronym>IVR</acronym>
							) endpoint provides access to an
							<acronym>IVR</acronym>
							service. Upon requests from the call agent,
							the
							<acronym>IVR</acronym>
							server
							<quote>plays</quote>
							announcements and tones, and
							<quote>listens</quote>
							for responses, such as (
							<acronym>DTMF</acronym>
							) input or voice messages, from the user. A
							given
							<acronym>IVR</acronym>
							endpoint is not expected to support more
							than one connection at a time. Similarly to
							announcement endpoints, IVR endpoints do not
							possess media-transcoding capabilities. IVR
							plays and records in the format in which the
							media was stored or received.
						</para>
					</listitem>
				</varlistentry>
				<varlistentry>
					<term>Conference Bridge Access Point</term>
					<listitem>
						<para>
							A conference bridge endpoint is used to
							provide access to a specific conference.
							Media gateways should be able to establish
							several connections between the endpoint and
							packet networks, or between the endpoint and
							other endpoints in the same gateway. The
							signals originating from these connections
							are mixed according to the connection
							<quote>mode</quote>
							(as specified later in this document). The
							precise number of connections that an
							endpoint supports is characteristic of the
							gateway, and may, in fact, vary according to
							the allocation of resources within the
							gateway.
						</para>
					</listitem>
				</varlistentry>
				<varlistentry>
					<term>Packet Relay Endpoint</term>
					<listitem>
						<para>
							A packet relay endpoint is a specific form
							of conference bridge that typically only
							supports two connections. Packet relays can
							be found in firewalls between a protected
							and an open network, or in transcoding
							servers used to provide interoperation
							between incompatible gateways, such as
							gateways which don't support compatible
							compression algorithms and gateways which
							operate over different transmission
							networks, such as IP or ATM.
						</para>
					</listitem>
				</varlistentry>
				<varlistentry>
					<term>Echo Endpoint</term>
					<listitem>
						<para>
							An echo—or loopback—endpoint is a test
							endpoint that is used for maintenance and/or
							continuity testing. The endpoint returns the
							incoming audio signal from the endpoint back
							to that same endpoint, thus creating an echo
							effect
						</para>
					</listitem>
				</varlistentry>
			</variablelist>
		</section>

		<section id="ittms-Controller-Modules">
			<title>Controller Modules</title>
			<para>
				Controller Modules allows external interfaces to be
				implemented for the Media Server. Each controller module
				implements an industry standard control protocol, and
				uses a generic SPI to control processing components or
				endpoints.
			</para>
			<para>
				One such controller module is the Media Gateway Control
				Protocol (MGCP). MGCP is designed as an internal
				protocol within a distributed system that appears to
				outside as a single VoIP gateway. The MGCP is composed
				of a Call Agent, and set of gateways including at least
				one "media gateway" which performs the conversion of media
				signal between circuit and packets, and atleast one
				"signalling gateway" when connected to SS7
				controlled network. The Call Agent can be distributed
				over several computer platforms.
			</para>
		</section>
	</section>

	<section id="ittms-Design_Overview">
		<title>Design Overview</title>


		<para>
			The Mobicents Media Server is developed on top of existing
			Java technologies. The Java platform is ideal for network
			computing. It offers single, unified-and-unifying
			programming model that can connect all elements of a
			business infrastructure. The modularization effort is
			supported by use of the JBoss Microcontainer which
			allows to deploy services written as Plain Java Objects into
			a Standard Java SE runtime environment in controlled manner
			and achieve great level of customization. Dependencies are
			fully managed to ensure that new services cannot be deployed
			until services they depend on have first been deployed.
			Where it makes sense to do so you can even re-deploy
			services at runtime providing that you access them via the
			microcontainer bus. Undeploying a service causes all
			dependent services to be undeployed first in order to
			maintain the integrity of the system.
		</para>

		<formalpara>
		<title>Media Source and Media Sink</title>
		<para>
			To achieve the modularization every media component's in
			Mobicents Media Server (like AudioPlayer, Recorder, DTMF
			Detector/Generator) are identified as either MediaSource or
			MediaSink. As name suggests MediaSource is the one that has
			capability to generate media (AudioPlayer) while MediaSink
			(Recorder) is the one that consumes media. 
		</para>
		</formalpara>	
		
		<formalpara>
		<title>Components and Factories</title>
		<para>
			For creating any component Media Server uses suitable
			Factory. Each component has its unique identifier and name
			defined by its factory. Component identifier is unique
			within the entire server implementation. The name of
			component in opposite way is shared across component
			produced by same factory.
		</para>
		</formalpara>	
		
		<formalpara>
		<title>Endpoint Composition</title>
		<para>
			Each of the Endpoints declared in Mobicents Media Server
			are composition of these Media Source/Sink and also depends
			on how each of these media components are ordered. For
			example which media component is first in line to
			consume/produce media. The transition of media through this
			ordered media components is achieved by Channels.
		</para>
		</formalpara>	
		
		
		<formalpara>
		<title>Channel</title>		
		<para>
			Channel is not a media component but it is able to join with
			Media Source and Media Sink or join with other channel.
			The role of channel is to construct media flow path by
			joining components using pipes.
		</para>
		</formalpara>
		
		<formalpara>
		<title>Pipe</title>				
		<para>
			Each Pipe has either inlet or outlet or both defined. A Pipe
			with only inlet defined acts as exhaust for a channel while
			Pipe with only outlet acts as intake for a Channel. If a
			Pipe has both inlet and outlet defined, it means its an
			internal pipe joining two components.
		</para>


			<mediaobject
				id="captms-mms-MMSControlAPI-dia-Session">
				<imageobject>
					<imagedata width="419" align="center" fileref="images/mms-ApplicationWiring-dia-Media_Flow_Path.png" format="PNG" />
				</imageobject>
			</mediaobject>


		<para>
			For example in diagram above Pipe1 (joining source and Component A) is the one with only
			outlet defined and Pipe3 (joinig sink and Component B) is the one with only inlet defined
			while Pipe2 (joining Component A and Component B) has both inlet and outlet defined and hence acts
			as internal pipe joining Component A and Component B.
		</para>
		</formalpara>
		
		<para>
			Endpoints may only decalre Channel to receive media
			(Rx-Channel) or Channel to send media (Tx-Channel) or
			Channel for both receiving as well as sending media.
		</para>
		<para>
			In addition to Channels, each Endpoints also has either
			MediaSource or MediaSink or both acting as primary
			source/sink of Media. If Endpoint doesn't have primary
			MediaSource or MediaSink it needs to declare the
			ResourceGroup which is a container for MediaSource and
			MediaSink. For exampl IVR Endpoint has both MediaSource and
			MediaSink while Conference Endpoint has ResourceGroup
			(ConferenceBridge)
		</para>
		
		
		<table id="tab-captms-mms-Component-Defintion"
				frame='all'>
				<title>Component Definition</title>
				<tgroup cols='5' align='left' colsep='1' rowsep='1'>
					<colspec colname='c1' />
					<colspec colname='c2' />
					<colspec colname='c3' />
					<colspec colname='c4' />
					<colspec colname='c5' />
					<thead>
						<row>
							<entry align="center">
								Component
							</entry>
							<entry align="center">Media Source</entry>
							<entry align="center">Media Sink</entry>
							<entry align="center">Component Factory</entry>
							<entry align="center">Description</entry>
						</row>
					</thead>
					<tbody>
						<row>
							<entry>AudioPlayer</entry>
							<entry>yes</entry>
							<entry>no</entry>
							<entry>org.mobicents.media.server.
							 impl.resource.
							 audio.AudioPlayerFactory</entry>
							<entry>AudioPlayer is capable of playing pcma, pcmu, speex, gsm, linear, linear 44100 mono, linear 44100 stero encoded files</entry>
						</row>
						<row>
							<entry>Recorder</entry>
							<entry>no</entry>
							<entry>yes</entry>
							<entry>org.mobicents.media.server. impl.resource.
							 audio.RecorderFactory</entry>
							<entry>Recorder is capable of recording in pcma, pcmu, linear formats</entry>
						</row>	
						<row>
							<entry>Rfc2833Detector</entry>
							<entry>no</entry>
							<entry>yes</entry>
							<entry>org.mobicents.media.server. impl.resource.
							 dtmf.Rfc2833DetectorFactory</entry>
							<entry>Rfc2833Detector is capable of detecting RFC2833 RTP Events. Basically used for DTMF detection.</entry>
						</row>	
						<row>
							<entry>Rfc2833Generator</entry>
							<entry>yes</entry>
							<entry>no</entry>
							<entry>org.mobicents.media.server. impl.resource.
							 dtmf.Rfc2833GeneratorFactory</entry>
							<entry>Rfc2833Generator is capable of generating RFC2833 RTP Events. Basically used for DTMF generation.</entry>
						</row>	
						
						<row>
							<entry>InbandDetector</entry>
							<entry>no</entry>
							<entry>yes</entry>
							<entry>org.mobicents.media.server. impl.resource.
							 dtmf.InbandDetectorFactory</entry>
							<entry>InbandDetector is capable of detecting inband DTMF. InbandDetector is mostly used when detecting DTMF from conventional SS7 line where as Rfc2833Detector is used only for IP netwrok</entry>
						</row>	
						<row>
							<entry>InbandGenerator</entry>
							<entry>yes</entry>
							<entry>no</entry>
							<entry>org.mobicents.media.server. impl.resource.
							 dtmf.InbandGeneratorFactory</entry>
							<entry>InbandGeneratorFactory is capable of generating inband DTMF. InbandGenerator is mostly used when generating DTMF on conventional SS7 line where as Rfc2833Generator is used only for IP netwrok</entry>
						</row>	
						<row>
							<entry>Player</entry>
							<entry>yes</entry>
							<entry>no</entry>
							<entry>org.mobicents.media.server. impl.resource.
							 audio.soundcard.PlayerFactory</entry>
							<entry>This is special kind of component to play the media directly on sound hardware installed on Media Server. The sound hardware is any hardware that can understand the Format of media arriving. For example to directly play media on audio card of computer where media server is running</entry>
						</row>						
						<row>
							<entry>Demultiplexer</entry>
							<entry>yes</entry>
							<entry>no</entry>
							<entry>org.mobicents.media.server. impl.resource.
							 DemuxFactory</entry>
							<entry>A Demultiplexer is one that has one media stream as input but can produce many media stream as output. For example Demultiplexer can be in path of IVR endpoint RxChannel and output's from Demultiplexer can be connected to InbandDetector as well as Rfc2833Detector using Pipe.</entry>
						</row>
						<row>
							<entry>Multiplexer</entry>
							<entry>no</entry>
							<entry>yes</entry>
							<entry>org.mobicents.media.server. impl.resource.
							 MuxFactory</entry>
							<entry>A Multiplexer is one that has many media stream's as input but will produce only one media stream as output. For example Multiplexer can be in path of IVR endpoint TxChannel and input's of Multiplexer can be connected to InbandGenerator as well as Rfc2833Generator using Pipe.</entry>
						</row>						
					</tbody>
				</tgroup>
			</table>

	</section>
	


</chapter>
